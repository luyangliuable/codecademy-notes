## Summary of Key Points in the Text

<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->
**Table of Contents**

- [Summary of Key Points in the Text](#summary-of-key-points-in-the-text)
    - [The Disparity of Depth](#the-disparity-of-depth)
        - [Psychophysical Power Law Exponents](#psychophysical-power-law-exponents)
        - [Mathematical Consideration](#mathematical-consideration)
        - [Perceptual Inaccuracy](#perceptual-inaccuracy)
        - [Figure 6.2 Explanation](#figure-62-explanation)
        - [Line-of-Sight Ambiguity](#line-of-sight-ambiguity)
        - [Viewing Limitations](#viewing-limitations)
    - [Occlusion Hides Information](#occlusion-hides-information)
        - [Depth Cue: Occlusion](#depth-cue-occlusion)
        - [Motion Parallax](#motion-parallax)
        - [3D Viewpoint in Synthetic Scenes](#3d-viewpoint-in-synthetic-scenes)
        - [Time Cost](#time-cost)
        - [Hidden Information Problem](#hidden-information-problem)
        - [Cognitive Load in Unfamiliar Scenes](#cognitive-load-in-unfamiliar-scenes)
        - [Visual Encoding Challenges](#visual-encoding-challenges)
        - [User Interaction](#user-interaction)
    - [Perspective Distortion Dangers](#perspective-distortion-dangers)
        - [Definition of Perspective Distortion](#definition-of-perspective-distortion)
        - [Historical Context: Western Art](#historical-context-western-art)
        - [Impact on Visual Encoding of Abstract Data](#impact-on-visual-encoding-of-abstract-data)
        - [Examples](#examples)
        - [Additional Example: Figure 6.5](#additional-example-figure-65)
        - [Overall Conclusion](#overall-conclusion)
    - [6.3.5 Other Depth Cues](#635-other-depth-cues)
        - [Familiar Object Size](#familiar-object-size)
        - [Shadows and Surface Shading](#shadows-and-surface-shading)
        - [Stereoscopic Depth](#stereoscopic-depth)
        - [Atmospheric Perspective](#atmospheric-perspective)
    - [Tilted Text Isn't Legible](#tilted-text-isnt-legible)
    - [Benefits of 3D: Shape Perception](#benefits-of-3d-shape-perception)
    - [Justification and Alternatives for 3D Visualization](#justification-and-alternatives-for-3d-visualization)
    - [No Unjustified 3D](#no-unjustified-3d)
    - [Rules of Thumb and Layer-Oriented Time-Series Vis](#rules-of-thumb-and-layer-oriented-time-series-vis)
    - [Empirical Evidence on 3D Visualization](#empirical-evidence-on-3d-visualization)
    - [No Unjustified 2D](#no-unjustified-2d)
        - [Strengths of 1D Lists](#strengths-of-1d-lists)
        - [Limitations of 2D Layouts](#limitations-of-2d-layouts)
        - [When to Use 2D](#when-to-use-2d)

<!-- markdown-toc end -->


### The Disparity of Depth

#### Psychophysical Power Law Exponents
- Different exponents for depth and planar judgements.
- For planar spatial position, exponent (n) is 1.0, indicating high accuracy.
- For depth judgements, n is 0.67, worse than 0.7 for area judgements.

#### Mathematical Consideration
- A line extending into depth is scaled nonlinearly, causing distortions in distances and angles.

#### Perceptual Inaccuracy
- Common intuition that we see the world in 3D is misleading.
- We actually see in 2.05D, according to Colin Ware.
- Most visual information is about a 2D image plane, and depth information is minimal.

#### Figure 6.2 Explanation
- Two axes (sideways and up-down) differ fundamentally from the depth axis (toward-away).
- For the two axes, millions of rays of information can be seen.
- For the depth axis, only one point of information is visible for each ray.

#### Line-of-Sight Ambiguity
- A phenomenon where only one point along the depth axis is available for each ray, limiting the depth information.

#### Viewing Limitations
- To get more information behind closest objects, the viewpoint or objects would have to move.
- May involve just moving the head or relocating the body to a different position.

### Occlusion Hides Information

#### Depth Cue: Occlusion
- Most powerful depth cue where objects **behind others are hidden**.
- Visible objects interpreted as closer than occluded ones.

#### Motion Parallax
- Changes in occlusion relationships as we move provide understanding of relative distances.
- Does not impose cognitive load in realistic scenes.

#### 3D Viewpoint in Synthetic Scenes
- Navigation controls allow for motion parallax.
- Interactive navigation is critical in complex scenes to understand 3D structure.

#### Time Cost
- **Interactive navigation** takes longer than inspecting a single image.

#### Hidden Information Problem
- Occlusion hides potentially important information.
- **Time-consuming to discover it via navigation**.

#### Cognitive Load in Unfamiliar Scenes
- Unpredictable and **unfamiliar shapes make understanding the structure challenging**.
- Requires internal memory and synthesis of understanding from previous viewpoints.

#### Visual Encoding Challenges
- Especially problematic when spatial position is used to represent nonspatial, abstract data.
- Figure 6.3 exemplifies the challenges in understanding a 3D nodeâ€“link graph.

#### User Interaction
- Sophisticated interaction idioms proposed to expedite the synthesis of understanding.

### Perspective Distortion Dangers

#### Definition of Perspective Distortion
- Distant objects appear smaller and change their planar position on the image plane.
- Also known as **foreshortening**.

#### Historical Context: Western Art
- Renaissance artists utilised the mathematics of perspective for realism.
- Perspective generally considered good in the context of art.

#### Impact on Visual Encoding of Abstract Data
- Perspective is harmful for visually encoding abstract data.
- Interferes with planar spatial position channels and size channel.

#### Examples
- Figure 6.4 shows difficulty in judging bar heights in 3D bar charts due to perspective distortion.

![](tm6X.png)

- Foreshortening makes direct comparison of bar heights difficult.

#### Additional Example: Figure 6.5
- Size coding in multiple dimensions leads to perspective distortion.
- Bar sizes in the distance cannot be directly compared due to the distortion.

#### Overall Conclusion
- Perspective distortion is a major issue in the context of data visualization.
- The power of the plane for visual encoding is lost.

### 6.3.5 Other Depth Cues

#### Familiar Object Size
- ðŸŸ¡`Depth cue` from the size of familiar objects in realistic scenes.
- Not available for visually encoded abstract data.

#### Shadows and Surface Shading
- ðŸŸ¡`Cast shadows` resolve depth ambiguity, help infer object height.
- ðŸŸ¡`Shading and self-shadowing` reveal 3D shape.
- Issues:
  - Creates visual clutter.
  - Can be mistaken for true marks.
  - Interfere with ðŸŸ¡`color channels` (highlights and shadows).

#### Stereoscopic Depth
- From disparities between two images made from slightly separated viewpoints.
- Considered a relatively ðŸŸ¡`weak depth cue` compared to others.
- Useful for nearby objects at the same depth.
- ðŸŸ¡`Stereo displays` improve depth perception accuracy.
- Doesn't solve problems with ðŸŸ¡`perspective distortion`.

#### Atmospheric Perspective
- ðŸŸ¡`Depth cue` where distant object color shifts toward blue.
- Conflicts with ðŸŸ¡`color encoding`.

ðŸŸ£ **Examples:**
- ðŸŸ£ Shadows help infer object height with respect to a ground plane.
- ðŸŸ£ Stereo displays provide different images for each eye to help resolve depth.

### Tilted Text Isn't Legible

- ðŸŸ¡`Text legibility` is dramatically impaired when text is tilted in 3D space.
- Text fonts are optimized for 2D pixel grids, leading to high legibility at small sizes.
- Hardware graphics acceleration enables quick rendering, but not necessarily good legibility for tilted text.
- Tilted text becomes ðŸŸ¡`blocky and jaggy` when moved off the image plane.
- Future solutions may come from careful rendering and high-resolution displays, but it remains a problem today.

ðŸŸ£ **Example:**
- ðŸŸ£ Text characters as small as nine pixels are easily readable in 2D but become less legible when tilted in 3D space.

### Benefits of 3D: Shape Perception
- ðŸŸ¡`3D visualization` shines when understanding three-dimensional geometric structures is fundamental to the viewer's task.
- Interactive navigation controls in 3D allow for quicker mental model construction compared to 2D axis-aligned views.
- The costs of 3D are outweighed when the benefit is understanding ðŸŸ¡`3D geometry`.

ðŸŸ£ **Examples:**
- ðŸŸ£ People trained to understand blueprints still find it challenging to synthesize a 3D mental model from 2D views.
- ðŸŸ£ 3D is more efficient for tasks involving inherently 3D spatial data, such as fluid flow over airplane wings, medical imaging, and molecular interactions within cells.

![](PwMG.png)
  
- ðŸŸ£ The use of 3D is justified for tasks like understanding fluid flow patterns, as geometric navigation based on 3D rotation can help users understand complex shapes quickly.


### Justification and Alternatives for 3D Visualization

- The use of ðŸŸ¡ `3D` for abstract data now demands careful justification, as the costs have become better understood.
- Often, a different approach at the ðŸŸ¡ `abstraction` or ðŸŸ¡ `visual encoding` levels could be more appropriate.

ðŸŸ£ **Example: Time-Series Data by van Wijk and van Selow**
  - The dataset has measurements of the number of people inside and power used in an office over a year.
  - A straightforward 3D representation showed only large-scale patterns, suffering from problems like occlusion and perspective distortion.
  - Authors use multiple linked ðŸŸ¡ `2D views` and different data abstraction, overcoming these issues.
  - Smaller-scale patterns, which were hidden in the 3D representation, become visible.

![](aThK.png)

### No Unjustified 3D

- 3D is only justifiable in certain cases, even for ðŸŸ¡ `abstract data`.

### Rules of Thumb and Layer-Oriented Time-Series Vis

ðŸŸ£ **Example: Oscilloscope Time-Series by Lopez-Hernandez et al.**
  - Uses 3D with care and justification.
  - The system starts with a traditional eye diagram, showing overlapping traces.
  - The metaphor of ðŸŸ£ "opening a drawer" is used to spread the traces apart.
  - Orthographically projected layers always face the viewer.
  - Navigation complexity is managed by auto-zooming and framing as user adjusts the orientation.


### Empirical Evidence on 3D Visualization

- ðŸŸ¡ `Empirical experiments` are crucial for understanding user performance in 2D vs 3D interfaces.
- There's a dissociation between stated preference for ðŸŸ¡ `3D` and actual task performance.
  
  ðŸŸ£ **Example: Study by Andre and Wickens 95**
  - 3D is better for shape understanding tasks.
  - 2D is superior for tasks requiring judgment of distances and angles between objects.

- Most tasks involving ðŸŸ¡ abstract data do not benefit from 3D.

  ðŸŸ£ **Example: 3D Cone Trees vs 2D Tree Browser**
  - The study found a significant time cost when using 3D [Cockburn and McKenzie 00].

- Experimental designs should be controlled to accurately measure the efficacy of ðŸŸ¡ 3D vs 2D.

  ðŸŸ£ **Example: 3D Data Mountain vs 2D Favorites Display**
  - Initially, 3D outperformed 2D [Robertson et al. 98].
  - A later study found no performance benefit for 3D when other factors were controlled [Cockburn and McKenzie 01].

  ![](qI0e.png)
  
  ðŸŸ£ **Example: 3D Landscapes vs 2D Point Cloud**
  - No benefits for using 3D landscapes over 2D point clouds [Tory et al. 07].
  
  ðŸŸ£ **Example: Points vs Landscapes in High-dimensional Data**
  - Points were superior for search and point estimation tasks.
  - 2D landscapes were better than 3D [Tory et al. 07].
  - Similar results in a follow-up study for a visual memory task [Tory et al. 09].

- Other terms for 3D landscapes include ðŸŸ¡ height field and ðŸŸ¡ terrain.
- ðŸŸ¡ `Contour plots` can be used alone or combined with 3D for a colored landscape.

### No Unjustified 2D

- Just like with 3D, laying out data in ðŸŸ¡ 2D space should also be explicitly justified.
- Compare 2D layouts with the alternative of ðŸŸ¡ 1D lists.

#### Strengths of 1D Lists
1. ðŸŸ¡ Information Density: Lists show the maximal amount of information in minimal space.
2. ðŸŸ¡ Lookup Tasks: Lists are excellent when ordered properly, such as in alphabetical order for label search.

  ðŸŸ£ **Example: Alphabetical Ordered List**
  - Effective for finding a known label quickly.
  
#### Limitations of 2D Layouts
1. ðŸŸ¡ Space Requirement: 2D layouts, like nodeâ€“link representations, require more space to show the same number of labels.

  ðŸŸ£ **Example: Node-Link Representation**
  - Requires user to hunt around the layout for a specific label unless a search capability is built in.

#### When to Use 2D
- ðŸŸ¡ Use 2D when the task requires understanding the topological structure of the network.
- Some tasks are handled well by ðŸŸ¡ linear lists, even if the original data has network structure.

### Eyes Beat Memory

- The principle is that using ðŸŸ¡ eyes to switch between different views imposes a lower ðŸŸ¡ cognitive load than using ðŸŸ¡ memory to compare views.

#### Cognitive Load in Single View Navigation

- Navigation within a single view places cognitive load on the viewer.
  
  ðŸŸ£ **Example 1: Navigational Choices**
  - If you zoomed into the nucleus, you have to remember that to maintain orientation.
  
  ðŸŸ£ **Example 2: Remembering Past Views**
  - If earlier all the stock options in the tech sector were in the top corner, you have to remember that.

#### Solution: External Representation

- Using an external representation like an overview window can minimize cognitive load.

  ðŸŸ£ **Example: Overview Window**
  - A small overview window with a rectangle showing the position and size of the current camera viewport for the main view allows you to just look and see your orientation, rather than needing to remember it.
  
### Memory and Attention

- ðŸŸ¡ Human memory is categorized into two types: 
  1. ðŸŸ¡ Long-term memory: Lasts a lifetime
  2. ðŸŸ¡ Short-term memory (Working memory): Lasts several seconds
  
- ðŸŸ¡ Working memory has a limited capacity, leading to ðŸŸ¡ cognitive load when limits are reached. 

- ðŸŸ¡ Human attention is also a limited resource.

  - ðŸŸ¡ Conscious search becomes harder with more items to check.
  
  - ðŸŸ¡ Vigilance degrades quickly during visual search tasks.
  
    ðŸŸ£ **Example**: Worse performance in visual search tasks after several hours compared to the first few minutes.


### Animation versus Side-by-Side Views

- ðŸŸ¡ Animation has multiple meanings:
  1. ðŸŸ¡ Narrative storytelling (e.g., in movies)
  2. ðŸŸ¡ Transitions between two states
  3. ðŸŸ¡ Video-style playback (play, pause, stop, rewind, step forward/back)

- ðŸŸ¡ Animation in vis (visualizations) is different from narrative storytelling in movies.
  
  - ðŸŸ£ **Example**: Movies guide viewer's eyes to one action at a time, while dataset animation might have simultaneous changes.

- ðŸŸ¡ Animation is powerful for transitions between two dataset configurations.
  
  - ðŸŸ£ **Example**: Helps in maintaining context and tracking object positions or camera viewpoints.
  
  - ðŸŸ¡ Limitation: Ineffective if many objects change between frames.

- ðŸŸ¡ We are blind to changes in areas that are not the focus of our attention.

- ðŸŸ¡ Jump cuts are hard to follow but can be useful if controlled by the user.
  
  - ðŸŸ£ **Example**: Blink comparator idiom used in astronomy to discover Pluto.

- ðŸŸ¡ Multiframe animations rely on internal memory for frame comparison.
  
  - ðŸŸ¡ Difficulty arises when many changes occur across many frames.
  
  - ðŸŸ¡ Pausing and replaying helps but doesn't fully solve the problem.

- ðŸŸ¡ Side-by-Side Views are often more effective for tasks requiring detailed frame comparison.

  - ðŸŸ¡ Suitable for dozens but not hundreds of frames.
  
  - ðŸŸ¡ Actions should be segmented into meaningful chunks.
  
  - ðŸŸ£ **Example**: Many vis idioms use multiple views, especially small multiples.

### Change Blindness

- ðŸŸ¡ Change Blindness: We fail to notice drastic changes if our attention is directed elsewhere.
  
  - ðŸŸ£ **Example**: An experiment where a person asking for directions is replaced by another person without the individual noticing.

- ðŸŸ¡ Implications for vis (visualizations): Difficulty in tracking complex and widespread changes across multiframe animations.

### Resolution over Immersion

- ðŸŸ¡ Pixels are Precious: Trade-off usually favors resolution over immersion.

- ðŸŸ¡ Immersive Environments: Use technology like stereo imagery, full six-degree-of-freedom head and position tracking.
  
  - ðŸŸ¡ Most Common Display: Head-mounted displays or rooms with rear-projection displays.
  
- ðŸŸ¡ Cost of Immersion:
  1. Lower Resolution
  2. Lack of workflow integration
  3. Physically taxing
  
  - ðŸŸ£ **Example**: Special-purpose settings that require users to leave their usual workspace.
  
- ðŸŸ¡ Critical Constraint in vis: The number of pixels available on a display.

- ðŸŸ¡ Rare Cases where Immersion is Useful:
  
  - ðŸŸ£ **Example**: Phobia desensitization in virtual reality.
  
  - ðŸŸ¡ When 3D spatial data is the chosen abstraction.
  
- ðŸŸ¡ Immersion for nonspatial, abstract data is uncommon and requires careful justification.


### Overview First, Zoom and Filter, Details on Demand

- ðŸŸ¡ Ben Shneiderman's Mantra: Emphasizes the need for an overview, the need for detail, and the role of data reduction and navigation.

- ðŸŸ¡ Vis Idiom for Overview: Provides a broad awareness of the entire information space with the goal to summarize.

  - ðŸŸ¡ No Navigation: Ideally, shows all items in the dataset simultaneously without the need for panning or scrolling.
  
- ðŸŸ¡ Role of Overviews:
  1. Help find regions for further investigation.
  2. Commonly shown at the beginning but also interleaved with detail views.
  
- ðŸŸ¡ When Dataset is Large: Use some form of reduce action to show everything.

  - ðŸŸ¡ Filtering and Aggregation: Two key methods for creating overviews.
  
  - ðŸŸ£ **Example**: Zooming out geometrically so the entire dataset is visible, possibly reducing the mark size to a single pixel.
  
  - ðŸŸ¡ Custom Overviews: More sophisticated than simple geometric zooming, driven implicitly by navigation.
  
- ðŸŸ¡ Overview vs Detail View:
  
  - ðŸŸ¡ Overview: Summarizes a lot of data.
  - ðŸŸ¡ Detail View: Shows fewer data items with more information.
  
  - ðŸŸ£ **Example**: Detail view pops up in response to a select action, or is permanently visible side-by-side with the overview.

- ðŸŸ¡ Other Idiom Families:
  1. Single view that dynamically changes by supporting reduce actions.
  2. Embed both detailed focus and overview context within a single view.
  
- ðŸŸ¡ Applicability: Mantra most useful for moderate-sized datasets.
  - ðŸŸ¡ Alternative for Large Datasets: "Search, Show Context, Expand on Demand", focuses on search results as a starting point for browsing.

## Responsiveness Is Required
ðŸŸ¡ **Latency of Interaction**: The time it takes for a system to respond to a user's action is extremely crucial in interaction design. 

ðŸŸ¡ **Discrete Categories**: Human reactions to latency are best understood in discrete categories, each with its own time constant.

ðŸŸ¡ **Responsive Systems**: A system will be considered responsive if it aligns with these latency categories and provides timely feedback to the user.

ðŸŸ¡ **Time Constants**: Three main time constants are critical for visual (vis) designers:

| ðŸŸ¡ Time Constant          | ðŸŸ¡ Value (in seconds) |
|--------------------------|-----------------------|
| Perceptual Processing    | 0.1                   |
| Immediate Response       | 1                     |
| Brief Tasks              | 10                    |

- ðŸŸ¡ **Perceptual Processing (0.1s)**: Relevant for things like screen updates.
  
- ðŸŸ¡ **Immediate Response (1s)**: Important for operations like visual feedback upon selecting an item with a mouse click, or animated transitions.

- ðŸŸ¡ **Brief Task (10s)**: Pertinent for breaking down complex tasks into simpler pieces with a good granularity.

> **Note**: 
> - ðŸŸ¡ Chapter 12 will cover multiple views.
> - ðŸŸ¡ Chapter 13 will cover approaches to data reduction.
> - ðŸŸ¡ Chapter 14 will cover focus+context idioms.

ðŸŸ£ **Examples**:
- **Perceptual Processing**: If a website updates its content within 0.1s, it appears highly responsive.
- **Immediate Response**: Clicking a button and instantly seeing a visual confirmation or change.
- **Brief Tasks**: Decomposing a long task, like a 60-second operation, into 10-second chunks.


## Visual Feedback
ðŸŸ¡ **Latency from User's Perspective**: The time between the user's action and receiving feedback from the system, indicating that the operation is complete.

ðŸŸ¡ **Visual Indication**: In visual systems, the feedback should be a visual change in the system's state, avoiding intrusive methods like console status messages or popup dialog boxes.

ðŸŸ¡ **Confirmation**: Users should get some form of confirmation that their action has completed to avoid confusion.

ðŸŸ¡ **Highlighting**: An effective method of providing visual feedback, such as highlighting a selected item.

ðŸŸ¡ **Immediate Response Latency Class**: Feedback should ideally occur within about one second to fit within this latency class.

ðŸŸ¡ **Progress Indicator**: If an action takes significantly longer than expected, showing some kind of progress indicator is advisable.

ðŸŸ¡ **Rule of Thumb**: Crossing from one latency class into another is a good indicator that a progress indicator should be shown.

> ðŸŸ¡ **Note**: This ties back to the latency classes described in Table 6.1 of section 6.8.

ðŸŸ£ **Examples**:
- **Visual Indication**: A button changes color to indicate it has been clicked.
- **Confirmation**: A selected item gets highlighted to confirm the operation is complete.
- **Immediate Response Latency Class**: A new frame in navigation is drawn within one second after the user changes the viewpoint.
- **Progress Indicator**: A loading spinner appears when a file is taking longer than usual to upload.


## Latency and Interaction Design
ðŸŸ¡ **Successful Interaction Design**: Involves matching latencies across low-level interaction mechanisms, visual feedback, system update time, and cognitive load of the operation.

### Low-Level Interaction Mechanisms
- ðŸŸ¡ **Clicking**: Slowest, requires the user to move the cursor and click on the target.
- ðŸŸ¡ **Mouseover with Dwell Time**: Speed depends on how long the cursor must dwell on the object.
- ðŸŸ¡ **Mouseover without Dwell Time**: Fastest, triggered as soon as the cursor crosses the object.

### Visual Feedback Mechanisms
- ðŸŸ¡ **Fixed Detail Pane**: High latency as it requires the user to move their eyes; but allows for detailed information.
- ðŸŸ¡ **Popup at Cursor**: Faster but might occlude other objects.
- ðŸŸ¡ **Visual Highlight in View**: Like highlighting neighbors in a graph, very immediate but can change the scene.

### System Update Time
- ðŸŸ¡ **Tiny Datasets**: Negligible latency.
- ðŸŸ¡ **Large Datasets**: Considerable latency unless optimized.
- ðŸŸ¡ **Distributed Datasets**: May take several seconds due to network latency.

ðŸŸ¡ **Algorithmic Attention**: Designing systems to guarantee immediate response may require specialized algorithms.

ðŸŸ¡ **User Experience**: When all latencies are well-matched, the user stays in a state of flow. Mismatches can disrupt this.

> ðŸŸ¡ **Note**: The term *rendering* is used in computer graphics for drawing an image. 

ðŸŸ£ **Examples**:
- **Clicking**: Moving mouse to a folder and clicking to open it.
- **Mouseover with Dwell Time**: Hovering over a hyperlink to display a preview.
- **Mouseover without Dwell Time**: Moving mouse over a menu item to immediately show sub-menus.
- **Fixed Detail Pane**: Clicking on an email to read its content in a pane on the side.
- **Popup at Cursor**: Hovering over a word to show its definition in a popup.
- **Visual Highlight in View**: Hovering over a node in a graph to highlight all connected nodes.
- **Tiny Datasets**: A locally-stored document opens almost instantly.
- **Large Datasets**: A complex 3D model takes time to load and render.
 **Distributed Datasets**: Fetching a file from a cloud server with high latency.

## Interactivity Costs

ðŸŸ¡ **Power and Cost of Interactivity**: Interaction allows users to explore larger information spaces but comes at the cost of human time and attention.

ðŸŸ¡ **Human-Powered Search**: If users have to manually check every possibility, the vis system's utility diminishes.

ðŸŸ¡ **Automatic Feature Detection**: A useful goal for designers to bring features of interest to the user's attention automatically via visual encoding.

ðŸŸ¡ **Trade-off**: There's always a balance between automatable aspects and the need for human pattern detection in interactive systems.

> ðŸŸ¡ **Note**: If a task can be fully automated, the need for a vis system becomes irrelevant.

ðŸŸ£ **Examples**:
- **Power of Interactivity**: Navigating through different layers of a complex dataset.
- **Cost of Interactivity**: Time spent manually filtering data points.
- **Human-Powered Search**: Manually checking each item in a list to find anomalies.
- **Automatic Feature Detection**: The system highlighting outliers in a dataset automatically.
- **Trade-off**: Choosing between an automated sorting algorithm and manual sort by a user to identify meaningful patterns.

## Get It Right in Black and White

ðŸŸ¡ **Design Guideline**: Maureen Stone suggests that effective use of color should start with black and white legibility.

ðŸŸ¡ **Legibility**: Crucial visual aspects should be understandable even when transformed from full color to black and white.

ðŸŸ¡ **Checking Work**: Validate design by literally viewing it in black and white, either via image processing or a black and white printer printout.

ðŸŸ¡ **Luminance Channel**: Focus on encoding the most important attributes with luminance to ensure contrast.

ðŸŸ¡ **Hue and Saturation**: These should be considered secondary sources of information.

> ðŸŸ¡ **Note**: The primary focus is to ensure the image is effective in black and white first before adding color.

ðŸŸ£ **Example**: 
- Before finalizing a colored heatmap, check its legibility by viewing it in black and white. Make sure the important data points are still distinguishable.

## Function First, Form Next

The priority in vis (visual representation) design should be on function first, followed by form.

### Rationale:

1. ðŸŸ¡ **Effective but Ugly**: An effective but aesthetically unpleasing design can be refined for beauty while keeping its effectiveness.
2. ðŸŸ¡ **Beautiful but Ineffective**: A beautiful yet ineffective design will likely need to be tossed out and redesigned from scratch.

ðŸŸ¡ **Collaboration**: A designer without graphic design training can collaborate with those who do to improve the form.

ðŸŸ¡ **Form Never**: The author doesn't advocate ignoring form altogether, as good visual form enhances effectiveness.

ðŸŸ¡ **Preference**: Given a choice between two equally effective systems, people will prefer the one with better visual form.

ðŸŸ¡ **Book's Focus**: The book emphasizes vis. effectiveness due to the scarcity of resources on this subject, rather than covering the principles of graphic design which are well-covered elsewhere.

ðŸŸ£ **Example**:
- Given two dashboards that display the same data effectively, users are more likely to engage with the one that also has a more visually appealing design.
